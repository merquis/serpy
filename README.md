# SERPY - Sistema de ExtracciÃ³n y AnÃ¡lisis de Contenido Web

SERPY es una aplicaciÃ³n web desarrollada con Streamlit que proporciona herramientas avanzadas para el scraping web, anÃ¡lisis de contenido y generaciÃ³n de artÃ­culos mediante IA.

## ğŸš€ CaracterÃ­sticas principales

- **Scraping de Google**: BÃºsqueda automatizada de URLs en Google con soporte multiidioma
- **ExtracciÃ³n de etiquetas SEO**: AnÃ¡lisis de tÃ­tulos, descripciones, H1, H2, H3, canonical, Open Graph
- **Scraping manual**: Procesamiento de listas de URLs personalizadas
- **AnÃ¡lisis de estructura**: ExtracciÃ³n jerÃ¡rquica de contenido (H1 â†’ H2 â†’ H3)
- **GeneraciÃ³n de artÃ­culos con IA**: CreaciÃ³n de contenido usando GPT-4
- **Chat con GPT**: Interfaz conversacional con modelos de OpenAI
- **AnÃ¡lisis de embeddings**: AnÃ¡lisis semÃ¡ntico de contenido
- **IntegraciÃ³n con Google Drive**: Almacenamiento y gestiÃ³n de archivos
- **Base de datos MongoDB**: Persistencia de datos y resultados

## ğŸ› ï¸ TecnologÃ­as utilizadas

- **Frontend**: Streamlit 1.45.1
- **HTTP Client**: httpx 0.28.1 (con fallback a Playwright)
- **Web Scraping**: BeautifulSoup4 4.13.4, Playwright 1.52.0
- **Anti-bot**: cloudscraper, undetected-chromedriver
- **IA**: OpenAI 1.82.0 (GPT-4)
- **Base de datos**: MongoDB (pymongo 4.13.0)
- **AnÃ¡lisis**: pandas 2.2.3, scikit-learn 1.6.1, spacy 3.8.7
- **OCR**: Tesseract, PyMuPDF 1.26.0

## ğŸ“‹ Requisitos previos

- Python 3.12+
- MongoDB (local o remoto)
- Cuenta de OpenAI con API key
- (Opcional) Token de BrightData para scraping avanzado
- (Opcional) Credenciales de Google Drive

## ğŸ”§ InstalaciÃ³n

### OpciÃ³n 1: InstalaciÃ³n local

1. Clonar el repositorio:
```bash
git clone https://github.com/tu-usuario/serpy.git
cd serpy
```

2. Instalar dependencias:
```bash
pip install -r requirements.txt
```

3. Instalar navegadores de Playwright:
```bash
playwright install
```

4. Configurar variables de entorno:
```bash
# Crear archivo .env o configurar en el sistema
OPENAI_API_KEY=tu_api_key
MONGODB_URI=mongodb://localhost:27017/
BRIGHTDATA_TOKEN=tu_token_opcional
```

5. Ejecutar la aplicaciÃ³n:
```bash
streamlit run streamlit_app.py
```

### OpciÃ³n 2: Docker

1. Construir la imagen:
```bash
docker build -t serpy .
```

2. Ejecutar el contenedor:
```bash
docker run -p 8501:8501 \
  -e OPENAI_API_KEY=tu_api_key \
  -e MONGODB_URI=mongodb://host.docker.internal:27017/ \
  serpy
```

## ğŸ“– Uso

1. Acceder a `http://localhost:8501`
2. Seleccionar la herramienta deseada en el menÃº lateral
3. Configurar los parÃ¡metros segÃºn la tarea
4. Ejecutar y descargar los resultados

### Herramientas disponibles:

- **ğŸ” Google Scraping**: BÃºsqueda automatizada de URLs
- **ğŸ·ï¸ Tag Scraping**: ExtracciÃ³n de estructura H1-H2-H3
- **ğŸ“ Manual Scraping**: AnÃ¡lisis de URLs personalizadas
- **âœï¸ Article Generator**: GeneraciÃ³n de contenido con IA
- **ğŸ’¬ GPT Chat**: Chat interactivo con GPT-4
- **ğŸ“Š Embeddings Analysis**: AnÃ¡lisis semÃ¡ntico avanzado

## ğŸ” ConfiguraciÃ³n

El sistema utiliza la clase `Config` en `config/settings.py` para gestionar:
- Tokens de API
- Conexiones a base de datos
- ParÃ¡metros de scraping
- ConfiguraciÃ³n de modelos de IA

## ğŸš¦ Sistema de Scraping Inteligente

SERPY implementa un sistema de scraping en dos niveles:

1. **Nivel 1 - httpx**: Cliente HTTP rÃ¡pido y eficiente
   - Headers dinÃ¡micos y rotaciÃ³n de User-Agent
   - GestiÃ³n inteligente de cookies
   - Reintentos automÃ¡ticos con backoff exponencial

2. **Nivel 2 - Playwright**: Para sitios con JavaScript o anti-bot
   - Navegador headless automatizado
   - EjecuciÃ³n de JavaScript
   - Captura de contenido dinÃ¡mico

## ğŸ” ConfiguraciÃ³n de Secretos en Easypanel

Para mantener los secretos seguros y seguir las mejores prÃ¡cticas, SERPY utiliza variables de entorno para gestionar las credenciales y configuraciones sensibles.

### ConfiguraciÃ³n en Easypanel

1. En tu panel de Easypanel, ve a la secciÃ³n "Entorno" de tu aplicaciÃ³n SERPY
2. AÃ±ade una variable de entorno llamada `STREAMLIT_SECRETS_TOML` 
3. Como valor, copia todo el contenido de tu archivo `secrets.toml` original

El formato debe ser similar a este ejemplo:

```
STREAMLIT_SECRETS_TOML='
[openai]
api_key = "sk-..."

[drive_service_account]
type = "service_account"
project_id = "..."
private_key_id = "..."
private_key = """-----BEGIN PRIVATE KEY-----
...
-----END PRIVATE KEY-----
"""
client_email = "..."
client_id = "..."
auth_uri = "https://accounts.google.com/o/oauth2/auth"
token_uri = "https://oauth2.googleapis.com/token"
auth_provider_x509_cert_url = "https://www.googleapis.com/oauth2/v1/certs"
client_x509_cert_url = "..."

[brightdata]
token = "..."
'
```

### Importante:
- No actives la opciÃ³n "Crear archivo .env"
- AsegÃºrate de incluir las comillas simples al inicio y final del valor
- DespuÃ©s de guardar, implementa los cambios para que se apliquen

### EjecuciÃ³n local (para desarrollo)

Si necesitas ejecutar la aplicaciÃ³n localmente durante el desarrollo:

1. Crea un directorio `.streamlit` en la raÃ­z del proyecto
2. Dentro de Ã©l, crea un archivo `secrets.toml` con tus credenciales
3. Ejecuta el proyecto con `streamlit run streamlit_app.py`

Este archivo `.streamlit/secrets.toml` estÃ¡ incluido en `.gitignore` para evitar que se suba a git.

## ğŸ“ Estructura del proyecto

```
serpy/
â”œâ”€â”€ config/              # ConfiguraciÃ³n y settings
â”œâ”€â”€ repositories/        # Capa de acceso a datos
â”œâ”€â”€ services/           # LÃ³gica de negocio
â”‚   â”œâ”€â”€ utils/         # Utilidades (httpx, playwright)
â”‚   â””â”€â”€ ...            # Servicios especÃ­ficos
â”œâ”€â”€ ui/                # Interfaz de usuario
â”‚   â”œâ”€â”€ components/    # Componentes reutilizables
â”‚   â””â”€â”€ pages/         # PÃ¡ginas de la aplicaciÃ³n
â”œâ”€â”€ streamlit_app.py   # Punto de entrada
â”œâ”€â”€ requirements.txt   # Dependencias
â””â”€â”€ Dockerfile        # ConfiguraciÃ³n Docker
```

## ğŸ¤ Contribuir

1. Fork el proyecto
2. Crear una rama para tu feature (`git checkout -b feature/AmazingFeature`)
3. Commit tus cambios (`git commit -m 'Add some AmazingFeature'`)
4. Push a la rama (`git push origin feature/AmazingFeature`)
5. Abrir un Pull Request

## ğŸ“ Licencia

Este proyecto estÃ¡ bajo la Licencia MIT - ver el archivo [LICENSE](LICENSE) para mÃ¡s detalles.

## ğŸ‘¥ Autores

- **Tu Nombre** - *Trabajo inicial* - [tu-usuario](https://github.com/tu-usuario)

## ğŸ™ Agradecimientos

- OpenAI por proporcionar los modelos GPT
- Streamlit por el framework de aplicaciones web
- La comunidad de Python por las excelentes librerÃ­as
