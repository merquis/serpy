# SERPY - Arquitectura de Microservicios

Sistema de scraping modular con mÃºltiples microservicios.

## ğŸ—ï¸ Estructura del Proyecto

```
serpy/
â”œâ”€â”€ scraper/              # Microservicio principal de scraping
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”œâ”€â”€ streamlit_app.py
â”‚   â””â”€â”€ ...
â”œâ”€â”€ images/               # Microservicio de procesamiento de imÃ¡genes (en desarrollo)
â”‚   â””â”€â”€ README.md
â”œâ”€â”€ docker-compose.yml    # Para desarrollo local
â””â”€â”€ MICROSERVICES_COMMUNICATION.md  # GuÃ­a de comunicaciÃ³n entre servicios
```

## ğŸš€ Microservicios Actuales

### 1. Scraper (Activo)
- **URL ProducciÃ³n**: https://serpy.videocursosweb.com/
- **Puerto Local**: 8501
- **TecnologÃ­a**: Python, Streamlit, Playwright
- **FunciÃ³n**: Interfaz web para scraping de Google, Booking.com, etc.

### 2. Images (En desarrollo)
- **URL ProducciÃ³n**: Por definir
- **Puerto Local**: 8502
- **TecnologÃ­a**: Python, FastAPI (propuesto)
- **FunciÃ³n**: Procesamiento y optimizaciÃ³n de imÃ¡genes

## ğŸ”§ ConfiguraciÃ³n en EasyPanel

### Para el servicio Scraper:
1. **Repositorio**: https://github.com/merquis/serpy
2. **Rama**: main
3. **Ruta de compilaciÃ³n**: `/scraper`
4. **Dockerfile**: AutomÃ¡tico (buscarÃ¡ en `/scraper/Dockerfile`)

### Para futuros servicios:
- Cada servicio serÃ¡ una app separada en EasyPanel
- Todos apuntan al mismo repositorio
- Diferente ruta de compilaciÃ³n para cada uno

## ğŸ”— ComunicaciÃ³n entre Microservicios

Los microservicios se comunican mediante HTTP REST:

### En ProducciÃ³n (EasyPanel):
```python
# Configurar como variable de entorno
IMAGES_SERVICE_URL=http://serpy-images.internal:8502
```

### En Desarrollo Local:
```python
# Docker Compose maneja la red interna
IMAGES_SERVICE_URL=http://images:8502
```

Ver [MICROSERVICES_COMMUNICATION.md](./MICROSERVICES_COMMUNICATION.md) para mÃ¡s detalles.

## ğŸ’» Desarrollo Local

### Requisitos:
- Docker
- Docker Compose

### Ejecutar todos los servicios:
```bash
# Clonar repositorio
git clone https://github.com/merquis/serpy.git
cd serpy

# Configurar variables de entorno
cp .env.example .env
# Editar .env con tus credenciales

# Iniciar servicios
docker-compose up -d

# Ver logs
docker-compose logs -f

# Detener servicios
docker-compose down
```

### Acceder a los servicios:
- Scraper: http://localhost:8501
- Images: http://localhost:8502 (cuando estÃ© implementado)

## ğŸ“ Variables de Entorno

### Scraper:
```env
STREAMLIT_SECRETS_TOML='
[mongodb]
uri = "mongodb://..."

[openai]
api_key = "sk-..."
'
```

### Images (futuro):
```env
SCRAPER_SERVICE_URL=http://scraper:8501
API_KEY=your-api-key
```

## ğŸš€ Despliegue

### OpciÃ³n 1: EasyPanel (Recomendado)
- Crear una app para cada microservicio
- Configurar la ruta de compilaciÃ³n correspondiente
- Las apps se comunican mediante URLs internas

### OpciÃ³n 2: VPS con Docker Compose
```bash
docker-compose up -d --build
```

## ğŸ“š DocumentaciÃ³n Adicional

- [ComunicaciÃ³n entre Microservicios](./MICROSERVICES_COMMUNICATION.md)
- [GuÃ­a de Despliegue](./DEPLOYMENT.md)

## ğŸ¤ Contribuir

1. Fork el repositorio
2. Crea tu rama de feature
3. Commit tus cambios
4. Push a la rama
5. Abre un Pull Request
