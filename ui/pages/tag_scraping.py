"""
P√°gina de UI para Scraping de Etiquetas HTML - Actualizada
"""
import streamlit as st
import json
import asyncio
from typing import Dict, Any, Optional
from ui.components.common import Card, Alert, Button, LoadingSpinner, DataDisplay
from services.tag_scraping_service import TagScrapingService
from services.drive_service import DriveService
from repositories.mongo_repository import MongoRepository
from config import config

class TagScrapingPage:
    """P√°gina para extraer estructura jer√°rquica de etiquetas HTML"""
    
    def __init__(self):
        self.tag_service = TagScrapingService()
        self.drive_service = DriveService()
        self.mongo_repo = MongoRepository(
            uri=st.secrets["mongodb"]["uri"],
            db_name=st.secrets["mongodb"]["db"]
        )
        self._init_session_state()
    
    def _init_session_state(self):
        """Inicializa el estado de la sesi√≥n"""
        if "json_content" not in st.session_state:
            st.session_state.json_content = None
        if "json_filename" not in st.session_state:
            st.session_state.json_filename = None
        if "tag_results" not in st.session_state:
            st.session_state.tag_results = None
        if "export_filename" not in st.session_state:
            st.session_state.export_filename = "etiquetas_jerarquicas.json"
        if "scraping_stats" not in st.session_state:
            st.session_state.scraping_stats = None
    
    def render(self):
        """Renderiza la p√°gina completa"""
        st.title("üè∑Ô∏è Scraping de Etiquetas HTML")
        st.markdown("### üìÅ Extrae estructura jer√°rquica (h1 ‚Üí h2 ‚Üí h3) desde archivo JSON")
        
        # Selector de fuente
        self._render_source_selector()
        
        # Mostrar configuraci√≥n si hay archivo cargado
        if st.session_state.json_content and not st.session_state.tag_results:
            self._render_processing_section()
        
        # Mostrar resultados si existen
        if st.session_state.tag_results:
            self._render_results_section()
    
    def _render_source_selector(self):
        """Renderiza el selector de fuente del archivo"""
        source = st.radio(
            "Selecciona fuente del archivo:",
            ["Desde Drive", "Desde ordenador"],
            horizontal=True,
            index=0
        )
        
        if source == "Desde ordenador":
            self._handle_file_upload()
        else:
            self._handle_drive_selection()
    
    def _handle_file_upload(self):
        """Maneja la carga de archivo desde el ordenador"""
        uploaded_file = st.file_uploader("Sube archivo JSON", type=["json"])
        
        if uploaded_file:
            st.session_state.json_content = uploaded_file.read()
            st.session_state.json_filename = uploaded_file.name
            st.session_state.tag_results = None
            st.session_state.scraping_stats = None
            Alert.success(f"Archivo {uploaded_file.name} cargado correctamente")
    
    def _handle_drive_selection(self):
        """Maneja la selecci√≥n de archivo desde Drive"""
        if "proyecto_id" not in st.session_state:
            Alert.error("Selecciona primero un proyecto en la barra lateral")
            return
        
        try:
            # Obtener subcarpeta
            folder_id = self.drive_service.get_or_create_folder(
                "scraping google",
                st.session_state.proyecto_id
            )
            
            # Listar archivos JSON
            files = self.drive_service.list_json_files_in_folder(folder_id)
            
            if not files:
                Alert.warning("No hay archivos JSON en la carpeta 'scraping google'")
                return
            
            # Selector de archivo
            file_names = list(files.keys())
            selected_file = st.selectbox("Selecciona un archivo de Drive", file_names)
            
            if Button.primary("Cargar archivo de Drive", icon=config.ui.icons["download"]):
                # Descargar contenido
                content = self.drive_service.get_file_content(files[selected_file])
                st.session_state.json_content = content
                st.session_state.json_filename = selected_file
                st.session_state.tag_results = None
                st.session_state.scraping_stats = None
                Alert.success(f"Archivo {selected_file} cargado desde Drive")
                
        except Exception as e:
            Alert.error(f"Error al acceder a Drive: {str(e)}")
    
    def _render_processing_section(self):
        """Renderiza la secci√≥n de procesamiento"""
        # Mostrar preview del JSON
        try:
            json_data = json.loads(st.session_state.json_content)
            
            with st.expander("üìÑ Vista previa del JSON cargado", expanded=False):
                st.json(json_data)
            
            # Configuraci√≥n de concurrencia
            max_concurrent = st.slider(
                "üîÅ Concurrencia m√°xima",
                min_value=1,
                max_value=10,
                value=5,
                help="N√∫mero m√°ximo de URLs procesadas simult√°neamente"
            )
            
            # Informaci√≥n sobre la estrategia
            st.info(
                "üí° **Estrategia de scraping optimizada:**\n"
                "- Intenta primero con httpx (r√°pido) para todas las URLs\n"
                "- Si falla o detecta protecci√≥n anti-bot, usa Playwright (robusto)\n"
                "- Procesa m√∫ltiples URLs simult√°neamente para mayor velocidad"
            )
            
            # Bot√≥n de procesamiento
            if Button.primary("Extraer estructura de etiquetas", icon="üîÑ"):
                self._process_urls(json_data, max_concurrent)
                
        except json.JSONDecodeError as e:
            Alert.error(f"Error al decodificar JSON: {str(e)}")
    
    def _process_urls(self, json_data: Any, max_concurrent: int):
        """Procesa las URLs del JSON"""
        # Contenedores para progreso
        progress_container = st.empty()
        status_container = st.container()
        
        # Contador de mensajes para mantener historial
        progress_messages = []
        
        def update_progress(message: str):
            # Agregar mensaje al historial (mantener √∫ltimos 5)
            progress_messages.append(message)
            if len(progress_messages) > 5:
                progress_messages.pop(0)
            
            # Actualizar display
            with progress_container.container():
                st.info(message)
                # Mostrar historial reciente
                with st.expander("üìä Historial de procesamiento", expanded=False):
                    for msg in progress_messages[-5:]:
                        st.caption(msg)
        
        with LoadingSpinner.show("Iniciando extracci√≥n de etiquetas..."):
            try:
                # Mostrar informaci√≥n inicial
                with status_container:
                    st.info(f"üöÄ Iniciando procesamiento con concurrencia m√°xima: {max_concurrent}")
                
                # Ejecutar scraping as√≠ncrono
                loop = asyncio.new_event_loop()
                asyncio.set_event_loop(loop)
                
                results = loop.run_until_complete(
                    self.tag_service.scrape_tags_from_json(
                        json_data,
                        max_concurrent=max_concurrent,
                        progress_callback=update_progress
                    )
                )
                
                st.session_state.tag_results = results
                
                # Guardar estad√≠sticas
                st.session_state.scraping_stats = {
                    "httpx_success": self.tag_service.successful_httpx_count,
                    "playwright_fallback": self.tag_service.playwright_fallback_count,
                    "total": self.tag_service.successful_httpx_count + self.tag_service.playwright_fallback_count
                }
                
                # Generar nombre de archivo de exportaci√≥n
                base_name = st.session_state.json_filename or "etiquetas"
                st.session_state.export_filename = base_name.replace(".json", "_ALL.json")
                
                # Contar URLs procesadas
                total_urls = sum(len(r.get("resultados", [])) for r in results)
                
                # Limpiar contenedores de progreso
                progress_container.empty()
                
                Alert.success(f"‚úÖ Se procesaron {total_urls} URLs exitosamente con concurrencia {max_concurrent}")
                st.rerun()
                
            except Exception as e:
                Alert.error(f"Error durante el procesamiento: {str(e)}")
            finally:
                loop.close()
    
    def _render_results_section(self):
        """Renderiza la secci√≥n de resultados"""
        results = st.session_state.tag_results
        
        # Mostrar estad√≠sticas de m√©todos de scraping
        if st.session_state.scraping_stats:
            self._render_scraping_stats()
        
        # Input para nombre de archivo
        st.session_state.export_filename = st.text_input(
            "üìÑ Nombre para exportar el archivo JSON",
            value=st.session_state.export_filename
        )
        
        # Botones de acci√≥n
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            self._render_download_button()
        
        with col2:
            self._render_drive_upload_button()
        
        with col3:
            self._render_mongodb_upload_button()
        
        with col4:
            if Button.secondary("Nueva extracci√≥n", icon=config.ui.icons["clean"]):
                self._clear_results()
        
        # Mostrar resultados
        self._display_results(results)
    
    def _render_scraping_stats(self):
        """Renderiza las estad√≠sticas de m√©todos de scraping"""
        stats = st.session_state.scraping_stats
        
        st.markdown("### üìä Estad√≠sticas de Scraping")
        
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric(
                "Total URLs", 
                stats["total"],
                help="Total de URLs procesadas"
            )
        
        with col2:
            st.metric(
                "httpx (r√°pido)", 
                stats["httpx_success"],
                f"{(stats['httpx_success']/stats['total']*100):.1f}%" if stats['total'] > 0 else "0%",
                delta_color="normal",
                help="URLs procesadas con httpx (m√©todo r√°pido)"
            )
        
        with col3:
            st.metric(
                "Playwright (robusto)", 
                stats["playwright_fallback"],
                f"{(stats['playwright_fallback']/stats['total']*100):.1f}%" if stats['total'] > 0 else "0%",
                delta_color="normal",
                help="URLs que requirieron Playwright (sitios con protecci√≥n)"
            )
        
        with col4:
            # Calcular tiempo promedio
            total_time = sum(
                r.get("scraping_time", 0) 
                for result in st.session_state.tag_results 
                for r in result.get("resultados", [])
            )
            avg_time = total_time / stats["total"] if stats["total"] > 0 else 0
            st.metric(
                "Tiempo promedio", 
                f"{avg_time:.2f}s",
                help="Tiempo promedio por URL"
            )
        
        st.divider()
    
    def _render_download_button(self):
        """Renderiza el bot√≥n de descarga"""
        # Convertir ObjectIds a strings antes de serializar
        results_for_json = self._prepare_results_for_json(st.session_state.tag_results)
        
        json_bytes = json.dumps(
            results_for_json,
            ensure_ascii=False,
            indent=2
        ).encode("utf-8")
        
        st.download_button(
            label="‚¨áÔ∏è Descargar JSON",
            data=json_bytes,
            file_name=st.session_state.export_filename,
            mime="application/json"
        )
    
    def _prepare_results_for_json(self, data):
        """Prepara los resultados para serializaci√≥n JSON convirtiendo ObjectIds a strings"""
        if isinstance(data, dict):
            return {k: self._prepare_results_for_json(v) for k, v in data.items()}
        elif isinstance(data, list):
            return [self._prepare_results_for_json(item) for item in data]
        elif hasattr(data, '__str__') and type(data).__name__ == 'ObjectId':
            return str(data)
        else:
            return data
    
    def _render_drive_upload_button(self):
        """Renderiza el bot√≥n de subida a Drive"""
        if Button.secondary("Subir a Drive", icon=config.ui.icons["upload"]):
            if "proyecto_id" not in st.session_state:
                Alert.warning("Selecciona un proyecto en la barra lateral")
                return
            
            try:
                # Convertir a JSON (convirtiendo ObjectIds a strings)
                results_for_json = self._prepare_results_for_json(st.session_state.tag_results)
                json_bytes = json.dumps(
                    results_for_json,
                    ensure_ascii=False,
                    indent=2
                ).encode("utf-8")
                
                # Obtener carpeta
                folder_id = self.drive_service.get_or_create_folder(
                    "scraping etiquetas html",
                    st.session_state.proyecto_id
                )
                
                # Subir archivo
                link = self.drive_service.upload_file(
                    st.session_state.export_filename,
                    json_bytes,
                    folder_id
                )
                
                if link:
                    Alert.success(f"Archivo subido: [Ver en Drive]({link})")
                else:
                    Alert.error("Error al subir archivo")
                    
            except Exception as e:
                Alert.error(f"Error al subir a Drive: {str(e)}")
    
    def _render_mongodb_upload_button(self):
        """Renderiza el bot√≥n de subida a MongoDB"""
        if Button.secondary("Subir a MongoDB", icon="üì§"):
            try:
                # Determinar si es un solo documento o m√∫ltiples
                data = st.session_state.tag_results
                
                if isinstance(data, list) and len(data) > 1:
                    # Insertar m√∫ltiples documentos
                    inserted_ids = self.mongo_repo.insert_many(
                        data,
                        collection_name="hoteles"
                    )
                    ids_formatted = "\n".join([f"- `{_id}`" for _id in inserted_ids])
                    Alert.success(
                        f"Subidos {len(inserted_ids)} documentos a MongoDB:\n\n{ids_formatted}"
                    )
                else:
                    # Insertar un solo documento
                    doc = data[0] if isinstance(data, list) else data
                    inserted_id = self.mongo_repo.insert_one(
                        doc,
                        collection_name="hoteles"
                    )
                    Alert.success(f"Documento subido a MongoDB con ID: `{inserted_id}`")
                    
            except Exception as e:
                Alert.error(f"Error al subir a MongoDB: {str(e)}")
    
    def _clear_results(self):
        """Limpia los resultados y el estado"""
        st.session_state.json_content = None
        st.session_state.json_filename = None
        st.session_state.tag_results = None
        st.session_state.export_filename = "etiquetas_jerarquicas.json"
        st.session_state.scraping_stats = None
        st.rerun()
    
    def _display_results(self, results: list):
        """Muestra los resultados del scraping"""
        st.subheader("üì¶ Resultados estructurados")
        
        # Resumen
        total_searches = len(results)
        total_urls = sum(len(r.get("resultados", [])) for r in results)
        
        col1, col2 = st.columns(2)
        with col1:
            st.metric("B√∫squedas procesadas", total_searches)
        with col2:
            st.metric("URLs analizadas", total_urls)
        
        # Mostrar resultados por b√∫squeda
        for result in results:
            search_term = result.get("busqueda", "Sin t√©rmino")
            urls_count = len(result.get("resultados", []))
            
            with st.expander(f"üîç {search_term} - {urls_count} URLs"):
                # Informaci√≥n de contexto
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.write(f"**Idioma:** {result.get('idioma', 'N/A')}")
                with col2:
                    st.write(f"**Regi√≥n:** {result.get('region', 'N/A')}")
                with col3:
                    st.write(f"**Dominio:** {result.get('dominio', 'N/A')}")
                
                # Resultados por URL
                for url_result in result.get("resultados", []):
                    self._display_url_result(url_result)
        
        # Mostrar JSON completo
        DataDisplay.json(
            results,
            title="JSON Completo",
            expanded=True
        )
    
    def _display_url_result(self, url_result: Dict[str, Any]):
        """Muestra el resultado de una URL individual"""
        url = url_result.get("url", "")
        status = url_result.get("status_code", "N/A")
        method = url_result.get("method", "unknown")
        scraping_time = url_result.get("scraping_time", 0)
        
        # Crear contenedor para la URL
        with st.container():
            # Header con URL, status y m√©todo
            col1, col2 = st.columns([3, 1])
            
            with col1:
                if status == "error":
                    st.markdown(f"‚ùå **{url}**")
                    st.caption(f"Error: {url_result.get('error', 'Unknown')}")
                else:
                    st.markdown(f"‚úÖ **{url}**")
            
            with col2:
                # Badges para m√©todo y tiempo
                method_emoji = "üöÄ" if method == "httpx" else "ü§ñ" if "playwright" in method else "‚ùì"
                st.caption(f"{method_emoji} {method} | ‚è±Ô∏è {scraping_time:.2f}s")
            
            # Mostrar estructura de encabezados si existe
            h1_data = url_result.get("h1", {})
            if h1_data and h1_data.get("titulo"):
                # H1
                st.markdown(f"### {h1_data['titulo']}")
                
                # H2s
                for h2 in h1_data.get("h2", []):
                    st.markdown(f"#### ‚Ü≥ {h2.get('titulo', '')}")
                    
                    # H3s
                    for h3 in h2.get("h3", []):
                        st.markdown(f"&nbsp;&nbsp;&nbsp;&nbsp;‚Ä¢ {h3.get('titulo', '')}")
            else:
                st.caption("‚ö†Ô∏è No se encontr√≥ estructura h1 en esta p√°gina")
            
            st.divider()
