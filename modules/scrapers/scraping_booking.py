# modules/scrapers/scraping_booking.py

import streamlit as st
# Importamos Playwright
from playwright.sync_api import sync_playwright
# No necesitamos ssl ni urllib.error directamente para la petici√≥n con Playwright
from bs4 import BeautifulSoup # BeautifulSoup todav√≠a nos puede ayudar a parsear el HTML obtenido por Playwright
import json
# Aseg√∫rate de que estos m√≥dulos existan y funcionen correctamente
# from modules.utils.drive_utils import subir_json_a_drive, obtener_o_crear_subcarpeta

# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# ‚öôÔ∏è Configuraci√≥n de la p√°gina de Streamlit
# Esta debe ser la PRIMERA llamada a Streamlit en el script principal
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
st.set_page_config(page_title="Scraper Booking (Playwright)", layout="wide")

# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# üì° Configuraci√≥n del proxy Bright Data
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# Es fundamental que estas credenciales y la URL del proxy sean correctas y est√©n activas
proxy_url = 'http://brd-customer-hl_bdec3e3e-zone-scraping_hoteles-country-es:9kr59typny7y@brd.superproxy.io:33335'

# La configuraci√≥n del proxy en Playwright se hace al lanzar el navegador o crear el contexto
# No necesitamos configurar un abridor global como con urllib.request

# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# üìÖ Funciones de Scraping (Usando Playwright)
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

def obtener_datos_booking(urls):
    """
    Extrae datos (nombre, valoraci√≥n, direcci√≥n, precio) de URLs de hotel de Booking.com
    usando Playwright para manejar JavaScript.

    Args:
        urls (list): Lista de URLs de p√°ginas de hotel de Booking.com.

    Returns:
        list: Lista de diccionarios con los datos extra√≠dos para cada URL.
    """
    resultados = []
    browser = None # Inicializar browser a None

    # Usamos sync_playwright para un uso s√≠ncrono dentro de la funci√≥n de Streamlit
    with sync_playwright() as p:
        st.info("üîÑ Intentando lanzar navegador Playwright...")
        try:
            # Lanzamos un navegador (Chromium es com√∫n)
            # headless=True para que no se abra una ventana visual (ideal para servidores)
            # Configuramos el proxy aqu√≠
            browser = p.chromium.launch(
                headless=True,
                proxy={
                    "server": proxy_url,
                    # Playwright maneja la autenticaci√≥n b√°sica directamente en la URL del servidor
                },
                 # Opcional: a√±adir args para entornos restringidos
                args=["--no-sandbox", "--disable-setuid-sandbox"]
            )
            st.success("‚úÖ Navegador Playwright lanzado con proxy.")
        except Exception as e:
            st.error(f"‚ùå Error al lanzar Playwright con proxy: {e}")
            st.info("Intentando lanzar Playwright sin proxy. El scraping podr√≠a fallar.")
            try:
                browser = p.chromium.launch(
                    headless=True,
                    args=["--no-sandbox", "--disable-setuid-sandbox"]
                )
                st.warning("‚ö†Ô∏è Playwright lanzado sin proxy.")
            except Exception as e_no_proxy:
                 st.error(f"‚ùå Error al lanzar Playwright sin proxy: {e_no_proxy}")
                 st.error("No se pudo lanzar Playwright. Aseg√∫rate de tenerlo instalado (`pip install playwright` y `playwright install`) y que el entorno soporte navegadores headless.")
                 return resultados # Salir si no se puede lanzar el navegador

        # Si el navegador se lanz√≥ con √©xito
        if browser:
            page = browser.new_page()

            # Opcional: Configurar un User-Agent si es necesario (Playwright usa uno por defecto)
            # page.set_extra_http_headers({'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'})

            for url in urls:
                st.info(f"üåê Navegando a: {url} con Playwright...")
                try:
                    # Navegar a la URL y esperar a que la red est√© inactiva
                    # Esto espera a que no haya actividad de red por un tiempo,
                    # lo que suele indicar que el JavaScript termin√≥ de cargar.
                    # Aumentamos el timeout
                    page.goto(url, wait_until="networkidle", timeout=90000) # Aumentar timeout a 90 segundos
                    st.success(f"‚úÖ P√°gina cargada: {url}")

                    # Ahora que la p√°gina est√° completamente cargada (incluyendo contenido JS),
                    # usamos los selectores para encontrar los elementos.
                    # Usamos page.locator() que es m√°s robusto en Playwright.
                    # A√±adimos esperas expl√≠citas para elementos clave

                    # --- Extraer Datos usando selectores CSS ---
                    # Selectores basados en data-testid (suelen ser m√°s estables) y fallbacks

                    # Nombre del Hotel
                    st.info("üîç Buscando t√≠tulo...")
                    # Esperar a que el elemento del t√≠tulo sea visible
                    nombre_hotel_element = page.locator('[data-testid="title"], h2.pp-header__title').first
                    try:
                        nombre_hotel_element.wait_for(state="visible", timeout=10000) # Esperar hasta 10 segundos
                        nombre_hotel = nombre_hotel_element.text_content().strip()
                        st.success(f"T√≠tulo encontrado: {nombre_hotel}")
                    except Exception:
                        nombre_hotel = None
                        st.warning("T√≠tulo no encontrado o no visible.")


                    # Valoraci√≥n Total
                    st.info("üîç Buscando valoraci√≥n...")
                    valoracion_container = page.locator('[data-testid="review-score"]').first
                    valoracion = None
                    try:
                        valoracion_container.wait_for(state="visible", timeout=10000) # Esperar contenedor
                        # Intentamos encontrar el elemento con la puntuaci√≥n num√©rica dentro del contenedor
                        # El selector .ac4a7896c7 es un ejemplo basado en estructuras vistas anteriormente, puede cambiar.
                        valoracion_score_element = valoracion_container.locator('.ac4a7896c7').first # Selector probable para el n√∫mero
                        if valoracion_score_element.count() > 0:
                            valoracion = valoracion_score_element.text_content().strip()
                        else:
                             # Si el selector espec√≠fico no funciona, intentamos obtener el texto completo del contenedor
                             valoracion = valoracion_container.text_content().strip()
                        st.success(f"Valoraci√≥n encontrada: {valoracion}")
                    except Exception:
                        valoracion = None
                        st.warning("Valoraci√≥n no encontrada o no visible.")


                    # Direcci√≥n
                    st.info("üîç Buscando direcci√≥n...")
                    direccion_element = page.locator('[data-testid="address"], span.hp_address_subtitle').first
                    direccion = None
                    try:
                        direccion_element.wait_for(state="visible", timeout=10000) # Esperar elemento
                        direccion = direccion_element.text_content().strip()
                        st.success(f"Direcci√≥n encontrada: {direccion}")
                    except Exception:
                        direccion = None
                        st.warning("Direcci√≥n no encontrada o no visible.")


                    # Precio Visible (para las fechas seleccionadas)
                    st.info("üîç Buscando precio...")
                    # Este es el m√°s propenso a ser din√°mico y variar.
                    precio_container = page.locator('[data-testid="price-and-discounted-price"], .prco-main-price').first
                    precio_minimo = None
                    try:
                        precio_container.wait_for(state="visible", timeout=10000) # Esperar contenedor
                        # Intentamos encontrar el elemento con el valor del precio dentro del contenedor
                        # El selector .bui-price-display__value es un ejemplo com√∫n.
                        precio_value_element = precio_container.locator('.bui-price-display__value').first
                        if precio_value_element.count() > 0:
                            precio_minimo = precio_value_element.text_content().strip()
                        else:
                             # Si el selector espec√≠fico no funciona, intentamos obtener el texto completo del contenedor
                             precio_minimo = precio_container.text_content().strip()
                        st.success(f"Precio encontrado: {precio_minimo}")
                    except Exception:
                        precio_minimo = None
                        st.warning("Precio no encontrado o no visible.")


                    # N√∫mero de Opiniones (Selector adicional)
                    st.info("üîç Buscando n√∫mero de opiniones...")
                    # Busca el elemento que contiene el n√∫mero total de opiniones.
                    # A menudo est√° cerca de la valoraci√≥n o en un bloque de opiniones.
                    # Deber√°s inspeccionar la p√°gina para encontrar el selector exacto.
                    # Ejemplo de selector basado en patrones comunes:
                    numero_opiniones_element = page.locator('.d8eab2cf7f.c90c0a70d3.db6369f3c6').first # Este selector es un ejemplo, ¬°inspecciona la p√°gina!
                    if numero_opiniones_element.count() == 0:
                         numero_opiniones_element = page.locator('.abf093bdfe.fa05109f31').first # Otro ejemplo

                    numero_opiniones = None
                    # No a√±adimos espera expl√≠cita aqu√≠ para no bloquear si no es crucial,
                    # pero podr√≠as hacerlo si este dato es esencial.
                    if numero_opiniones_element.count() > 0:
                         numero_opiniones = numero_opiniones_element.text_content().strip()
                         st.success(f"N√∫mero de opiniones encontrado: {numero_opiniones}")
                    else:
                         st.warning("N√∫mero de opiniones no encontrado.")
                    # Podr√≠as necesitar procesar el texto para extraer solo el n√∫mero si incluye "X opiniones"


                    # A√±adir los resultados a la lista
                    resultados.append({
                        "nombre_hotel": nombre_hotel,
                        # Estos campos est√°n hardcodeados en tu c√≥digo original.
                        # Si var√≠an en la URL, deber√≠as extraerlos de la URL o manejarlos de otra forma.
                        "aid": "linkafiliado",
                        "checkin": "2025-05-15",
                        "checkout": "2025-05-16",
                        "group_adults": "2",
                        "group_children": "0",
                        "no_rooms": "1",
                        "dest_id": "-369166",
                        "dest_type": "city",
                        # --- Datos extra√≠dos con Playwright ---
                        "valoracion": valoracion,
                        "numero_opiniones": numero_opiniones,
                        "direccion": direccion,
                        "precio_minimo": precio_minimo,
                        "url": url
                    })
                    st.success(f"‚úÖ Proceso de extracci√≥n completado para: {url}")

                except Exception as e:
                    st.error(f"‚ùå Error procesando {url} con Playwright: {e}")
                    # Intentar obtener el contenido de la p√°gina al momento del error para depuraci√≥n
                    try:
                        st.text(f"Contenido de la p√°gina (primeros 1000 chars) al momento del error:\n{page.content()[:1000]}...")
                    except Exception as content_e:
                        st.warning(f"No se pudo obtener el contenido de la p√°gina para depuraci√≥n: {content_e}")

                    resultados.append({"url": url, "error": f"Error de procesamiento con Playwright: {e}"})

            # Cerramos el navegador al finalizar el bucle de URLs
            browser.close()

    return resultados

# Nota: Las funciones subir_resultado_a_drive y obtener_o_crear_subcarpeta
# no est√°n incluidas aqu√≠ ya que dependen de tu implementaci√≥n espec√≠fica de Google Drive.
# Aseg√∫rate de que est√©n correctamente definidas en modules.utils.drive_utils

# def subir_resultado_a_drive(nombre_archivo, contenido_bytes):
#     # ... tu implementaci√≥n ...
#     pass

# def obtener_o_crear_subcarpeta(nombre_subcarpeta, parent_folder_id):
#     # ... tu implementaci√≥n ...
#     pass


def render_scraping_booking():
    """
    Renderiza la interfaz de usuario de Streamlit para el scraper de Booking.com.
    """
    st.session_state["_called_script"] = "scraping_booking"
    st.title("üè® Scraping de datos de hoteles en Booking (modo Playwright)")
    st.info("‚ÑπÔ∏è Este scraper usa Playwright para manejar contenido cargado con JavaScript.")
    st.warning("‚ö†Ô∏è Si no se muestran resultados, verifica la instalaci√≥n de Playwright (`pip install playwright` y `playwright install`) y las dependencias del navegador en tu entorno.")


    # Inicializar estados de sesi√≥n si no existen
    if "urls_input" not in st.session_state:
        st.session_state.urls_input = "https://www.booking.com/hotel/es/hotelvinccilaplantaciondelsur.es.html?aid=linkafiliado&checkin=2025-05-15&checkout=2025-05-16&group_adults=2&group_children=0&no_rooms=1&dest_id=-369166&dest_type=city"
    if "resultados_json" not in st.session_state:
        st.session_state.resultados_json = []

    # √Årea de texto para URLs
    st.session_state.urls_input = st.text_area(
        "üìù Pega una o varias URLs de Booking (una por l√≠nea):",
        st.session_state.urls_input,
        height=150
    )

    # Botones de acci√≥n
    col1, col2, col3 = st.columns([1, 1, 1])

    with col1:
        buscar_btn = st.button("üîç Scrapear Datos Hotel", key="buscar_datos_hotel")

    # Mostrar botones de exportar/subir solo si hay resultados
    if st.session_state.resultados_json:
        nombre_archivo = "datos_hoteles_booking_playwright.json" # Nombre de archivo diferente para distinguir
        contenido_json = json.dumps(st.session_state.resultados_json, ensure_ascii=False, indent=2).encode("utf-8")

        with col2:
            st.download_button(
                label="‚¨áÔ∏è Exportar JSON",
                data=contenido_json,
                file_name=nombre_archivo,
                mime="application/json",
                key="descargar_json"
            )

        # Aseg√∫rate de que la funci√≥n subir_resultado_a_drive est√© disponible
        # if 'subir_json_a_drive' in globals(): # Comprueba si la funci√≥n de Drive est√° definida/importada
        with col3:
            subir_a_drive_btn = st.button("‚òÅÔ∏è Subir a Google Drive", key="subir_drive_booking")
            if subir_a_drive_btn:
                # Aseg√∫rate de que las funciones de Drive est√©n importadas y disponibles
                try:
                    from modules.utils.drive_utils import subir_json_a_drive, obtener_o_crear_subcarpeta
                    with st.spinner("‚òÅÔ∏è Subiendo JSON a Google Drive (cuenta de servicio)..."):
                        subir_resultado_a_drive(nombre_archivo, contenido_json)
                except ImportError:
                     st.error("‚ùå Las funciones de Google Drive no est√°n disponibles. Aseg√∫rate de que 'modules.utils.drive_utils' est√© correctamente configurado.")


    # L√≥gica para ejecutar el scraping al presionar el bot√≥n
    if buscar_btn and st.session_state.urls_input:
        urls = [url.strip() for url in st.session_state.urls_input.split("\n") if url.strip()]
        if urls: # Asegurarse de que hay URLs despu√©s de limpiar
            with st.spinner("üîÑ Scrapeando datos de hoteles con Playwright..."):
                # Llama a la funci√≥n de scraping usando Playwright
                resultados = obtener_datos_booking(urls)
                st.session_state.resultados_json = resultados
            # Usar rerun para actualizar la interfaz y mostrar los resultados/botones
            st.experimental_rerun()
        else:
            st.warning("Por favor, introduce al menos una URL.")


    # Mostrar resultados en formato JSON si existen
    if st.session_state.resultados_json:
        st.subheader("üì¶ Resultados obtenidos")
        st.json(st.session_state.resultados_json)

# Ejemplo de c√≥mo podr√≠as llamar a render_scraping_booking si este archivo es el script principal de Streamlit
# if __name__ == "__main__":
#     render_scraping_booking()
