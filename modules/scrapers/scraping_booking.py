# modules/scrapers/scraping_booking.py

import streamlit as st
import requests
from bs4 import BeautifulSoup


def render_scraping_booking():
    st.header("ğŸ“¦ Scraping de Hoteles en Booking (BeautifulSoup)")

    st.markdown("### âœï¸ ParÃ¡metros de bÃºsqueda")
    location = st.text_input("ğŸ“ Ciudad destino", "Tenerife")

    if st.button("ğŸ“¥ Obtener datos de los hoteles"):
        url = f"https://www.booking.com/searchresults.es.html?ss={location.replace(' ', '+')}"
        st.write(f"ğŸ”— URL utilizada: {url}")

        headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
                          "AppleWebKit/537.36 (KHTML, like Gecko) "
                          "Chrome/117.0.0.0 Safari/537.36"
        }

        try:
            response = requests.get(url, headers=headers)
            soup = BeautifulSoup(response.text, "html.parser")

            bloques = soup.select('div[data-testid="property-card"]')
            st.subheader("ğŸ§© Vista previa de bloques de hotel (property-card):")
            for b in bloques[:5]:
                st.code(str(b), language="html")
            resultados = []

            for bloque in bloques:
                enlace_tag = bloque.select_one('a[href]')
                titulo_tag = bloque.select_one('div[data-testid="title"]')

                if enlace_tag and titulo_tag:
                    nombre = titulo_tag.get_text(strip=True)
                    enlace = enlace_tag["href"]
                    if enlace.startswith("/"):
                        enlace = "https://www.booking.com" + enlace

                    resultados.append((nombre, enlace))

            if resultados:
                st.subheader("ğŸ¨ Nombres de hoteles encontrados:")
                for nombre, enlace in resultados[:10]:
                    st.markdown(f"### ğŸ¨ [{nombre}]({enlace})")
            else:
                st.warning("âš ï¸ No se pudieron encontrar nombres de hoteles en el HTML.")

        except Exception as e:
            st.error(f"âŒ Error durante el scraping: {e}")
