# modules/scrapers/scraping_booking.py

import streamlit as st
# Importamos Playwright en lugar de urllib.request
from playwright.sync_api import sync_playwright # Usamos la versi√≥n s√≠ncrona para Streamlit
# No necesitamos ssl ni urllib.error directamente para la petici√≥n con Playwright
from bs4 import BeautifulSoup # BeautifulSoup todav√≠a nos puede ayudar a parsear el HTML obtenido por Playwright
import json
# Aseg√∫rate de que estos m√≥dulos existan y funcionen correctamente
# from modules.utils.drive_utils import subir_json_a_drive, obtener_o_crear_subcarpeta

# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# ‚öôÔ∏è Configuraci√≥n de la p√°gina de Streamlit
# Esta debe ser la PRIMERA llamada a Streamlit en el script principal
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
st.set_page_config(page_title="Scraper Booking (Playwright)", layout="wide")

# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# üì° Configuraci√≥n del proxy Bright Data
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# Es fundamental que estas credenciales y la URL del proxy sean correctas y est√©n activas
proxy_url = 'http://brd-customer-hl_bdec3e3e-zone-scraping_hoteles-country-es:9kr59typny7y@brd.superproxy.io:33335'

# La configuraci√≥n del proxy en Playwright se hace al lanzar el navegador o crear el contexto
# No necesitamos configurar un abridor global como con urllib.request

# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# üìÖ Funciones de Scraping (Usando Playwright)
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

def obtener_datos_booking(urls):
    """
    Extrae datos (nombre, valoraci√≥n, direcci√≥n, precio) de URLs de hotel de Booking.com
    usando Playwright para manejar JavaScript.

    Args:
        urls (list): Lista de URLs de p√°ginas de hotel de Booking.com.

    Returns:
        list: Lista de diccionarios con los datos extra√≠dos para cada URL.
    """
    resultados = []

    # Usamos sync_playwright para un uso s√≠ncrono dentro de la funci√≥n de Streamlit
    with sync_playwright() as p:
        # Lanzamos un navegador (Chromium es com√∫n)
        # headless=True para que no se abra una ventana visual (ideal para servidores)
        # Configuramos el proxy aqu√≠
        try:
            browser = p.chromium.launch(
                headless=True,
                proxy={
                    "server": proxy_url,
                    # Playwright maneja la autenticaci√≥n b√°sica directamente en la URL del servidor
                }
            )
            st.success("‚úÖ Navegador Playwright lanzado con proxy.")
        except Exception as e:
            st.error(f"‚ùå Error al lanzar Playwright con proxy: {e}")
            st.info("Intentando lanzar Playwright sin proxy. El scraping podr√≠a fallar.")
            try:
                browser = p.chromium.launch(headless=True)
                st.warning("‚ö†Ô∏è Playwright lanzado sin proxy.")
            except Exception as e_no_proxy:
                 st.error(f"‚ùå Error al lanzar Playwright sin proxy: {e_no_proxy}")
                 st.error("No se pudo lanzar Playwright. Aseg√∫rate de tenerlo instalado (`pip install playwright` y `playwright install`).")
                 return resultados # Salir si no se puede lanzar el navegador


        # Creamos una nueva p√°gina (tab) en el navegador
        page = browser.new_page()

        # Opcional: Configurar un User-Agent si es necesario (Playwright usa uno por defecto)
        # page.set_extra_http_headers({'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'})


        for url in urls:
            st.info(f"üåê Navegando a: {url} con Playwright...")
            try:
                # Navegar a la URL y esperar a que la red est√© inactiva
                # Esto espera a que no haya actividad de red por un tiempo,
                # lo que suele indicar que el JavaScript termin√≥ de cargar.
                page.goto(url, wait_until="networkidle", timeout=60000) # Aumentar timeout si es necesario (en ms)
                st.success(f"‚úÖ P√°gina cargada: {url}")

                # Ahora que la p√°gina est√° completamente cargada (incluyendo contenido JS),
                # usamos los selectores para encontrar los elementos.
                # Usamos page.locator() que es m√°s robusto en Playwright.

                # --- Extraer Datos usando selectores CSS ---
                # Selectores basados en data-testid (suelen ser m√°s estables) y fallbacks

                # Nombre del Hotel
                # Busca primero por data-testid="title", si no, por h2.pp-header__title
                # .first para obtener el primer elemento si hay m√∫ltiples coincidencias
                nombre_hotel_element = page.locator('[data-testid="title"], h2.pp-header__title').first
                # .text_content() es similar a .text en BeautifulSoup pero para Playwright
                nombre_hotel = nombre_hotel_element.text_content().strip() if nombre_hotel_element.count() > 0 else None


                # Valoraci√≥n Total
                # Buscamos el contenedor de la valoraci√≥n.
                # Luego, dentro de ese contenedor, buscamos el elemento espec√≠fico que tiene la puntuaci√≥n num√©rica.
                # Deber√°s inspeccionar la p√°gina (F12) para confirmar el selector exacto del n√∫mero dentro de [data-testid="review-score"]
                # El selector .ac4a7896c7 es un ejemplo basado en estructuras vistas anteriormente, puede cambiar.
                valoracion_container = page.locator('[data-testid="review-score"]').first
                valoracion = None
                if valoracion_container.count() > 0:
                    # Intentamos encontrar el elemento con la puntuaci√≥n num√©rica dentro del contenedor
                    valoracion_score_element = valoracion_container.locator('.ac4a7896c7').first # Selector probable para el n√∫mero
                    if valoracion_score_element.count() == 0:
                        # Si el selector espec√≠fico no funciona, intentamos obtener el texto completo del contenedor
                        valoracion = valoracion_container.text_content().strip()
                    else:
                         valoracion = valoracion_score_element.text_content().strip()


                # Direcci√≥n
                # Busca primero por data-testid="address", si no, por span.hp_address_subtitle
                direccion_element = page.locator('[data-testid="address"], span.hp_address_subtitle').first
                direccion = direccion_element.text_content().strip() if direccion_element.count() > 0 else None

                # Precio Visible (para las fechas seleccionadas)
                # Este es el m√°s propenso a ser din√°mico y variar.
                # Buscamos el contenedor principal del precio visible para las fechas.
                # Luego, dentro de ese contenedor, buscamos el elemento espec√≠fico que tiene el valor num√©rico del precio.
                # Deber√°s inspeccionar la p√°gina (F12) para confirmar el selector exacto del precio.
                precio_container = page.locator('[data-testid="price-and-discounted-price"], .prco-main-price').first
                precio_minimo = None
                if precio_container.count() > 0:
                    # Intentamos encontrar el elemento con el valor del precio dentro del contenedor
                    # El selector .bui-price-display__value es un ejemplo com√∫n.
                    precio_value_element = precio_container.locator('.bui-price-display__value').first
                    if precio_value_element.count() > 0:
                        precio_minimo = precio_value_element.text_content().strip()
                    else:
                         # Si el selector espec√≠fico no funciona, intentamos obtener el texto completo del contenedor
                         precio_minimo = precio_container.text_content().strip()


                # N√∫mero de Opiniones (Selector adicional)
                # Busca el elemento que contiene el n√∫mero total de opiniones.
                # A menudo est√° cerca de la valoraci√≥n o en un bloque de opiniones.
                # Deber√°s inspeccionar la p√°gina para encontrar el selector exacto.
                # Ejemplo de selector basado en patrones comunes:
                numero_opiniones_element = page.locator('.d8eab2cf7f.c90c0a70d3.db6369f3c6').first # Este selector es un ejemplo, ¬°inspecciona la p√°gina!
                if numero_opiniones_element.count() == 0:
                     numero_opiniones_element = page.locator('.abf093bdfe.fa05109f31').first # Otro ejemplo

                numero_opiniones = numero_opiniones_element.text_content().strip() if numero_opiniones_element.count() > 0 else None
                # Podr√≠as necesitar procesar el texto para extraer solo el n√∫mero si incluye "X opiniones"


                # A√±adir los resultados a la lista
                resultados.append({
                    "nombre_hotel": nombre_hotel,
                    # Estos campos est√°n hardcodeados en tu c√≥digo original.
                    # Si var√≠an en la URL, deber√≠as extraerlos de la URL o manejarlos de otra forma.
                    "aid": "linkafiliado",
                    "checkin": "2025-05-15",
                    "checkout": "2025-05-16",
                    "group_adults": "2",
                    "group_children": "0",
                    "no_rooms": "1",
                    "dest_id": "-369166",
                    "dest_type": "city",
                    # --- Datos extra√≠dos con Playwright ---
                    "valoracion": valoracion,
                    "numero_opiniones": numero_opiniones,
                    "direccion": direccion,
                    "precio_minimo": precio_minimo,
                    "url": url
                })
                st.success(f"‚úÖ Datos extra√≠dos con Playwright para: {url}")

            except Exception as e:
                st.error(f"‚ùå Error procesando {url} con Playwright: {e}")
                # Opcional: Imprimir el HTML renderizado por Playwright para depuraci√≥n
                # try:
                #     st.text(f"Contenido de la p√°gina (primeros 1000 chars) al momento del error:\n{page.content()[:1000]}...")
                # except Exception as content_e:
                #     st.warning(f"No se pudo obtener el contenido de la p√°gina para depuraci√≥n: {content_e}")

                resultados.append({"url": url, "error": f"Error de procesamiento con Playwright: {e}"})

        # Cerramos el navegador al finalizar el bucle
        browser.close()

    return resultados

# Nota: Las funciones subir_resultado_a_drive y obtener_o_crear_subcarpeta
# no est√°n incluidas aqu√≠ ya que dependen de tu implementaci√≥n espec√≠fica de Google Drive.
# Aseg√∫rate de que est√©n correctamente definidas en modules.utils.drive_utils

# def subir_resultado_a_drive(nombre_archivo, contenido_bytes):
#     # ... tu implementaci√≥n ...
#     pass

# def obtener_o_crear_subcarpeta(nombre_subcarpeta, parent_folder_id):
#     # ... tu implementaci√≥n ...
#     pass


def render_scraping_booking():
    """
    Renderiza la interfaz de usuario de Streamlit para el scraper de Booking.com.
    """
    st.session_state["_called_script"] = "scraping_booking"
    st.title("üè® Scraping de datos de hoteles en Booking (modo Playwright)")
    st.info("‚ÑπÔ∏è Este scraper usa Playwright para manejar contenido cargado con JavaScript.")

    # Inicializar estados de sesi√≥n si no existen
    if "urls_input" not in st.session_state:
        st.session_state.urls_input = "https://www.booking.com/hotel/es/hotelvinccilaplantaciondelsur.es.html?aid=linkafiliado&checkin=2025-05-15&checkout=2025-05-16&group_adults=2&group_children=0&no_rooms=1&dest_id=-369166&dest_type=city"
    if "resultados_json" not in st.session_state:
        st.session_state.resultados_json = []

    # √Årea de texto para URLs
    st.session_state.urls_input = st.text_area(
        "üìù Pega una o varias URLs de Booking (una por l√≠nea):",
        st.session_state.urls_input,
        height=150
    )

    # Botones de acci√≥n
    col1, col2, col3 = st.columns([1, 1, 1])

    with col1:
        buscar_btn = st.button("üîç Scrapear Datos Hotel", key="buscar_datos_hotel")

    # Mostrar botones de exportar/subir solo si hay resultados
    if st.session_state.resultados_json:
        nombre_archivo = "datos_hoteles_booking_playwright.json" # Nombre de archivo diferente para distinguir
        contenido_json = json.dumps(st.session_state.resultados_json, ensure_ascii=False, indent=2).encode("utf-8")

        with col2:
            st.download_button(
                label="‚¨áÔ∏è Exportar JSON",
                data=contenido_json,
                file_name=nombre_archivo,
                mime="application/json",
                key="descargar_json"
            )

        # Aseg√∫rate de que la funci√≥n subir_resultado_a_drive est√© disponible
        # if 'subir_json_a_drive' in globals(): # Comprueba si la funci√≥n de Drive est√° definida/importada
        with col3:
            subir_a_drive_btn = st.button("‚òÅÔ∏è Subir a Google Drive", key="subir_drive_booking")
            if subir_a_drive_btn:
                # Aseg√∫rate de que las funciones de Drive est√©n importadas y disponibles
                try:
                    from modules.utils.drive_utils import subir_json_a_drive, obtener_o_crear_subcarpeta
                    with st.spinner("‚òÅÔ∏è Subiendo JSON a Google Drive (cuenta de servicio)..."):
                        subir_resultado_a_drive(nombre_archivo, contenido_json)
                except ImportError:
                     st.error("‚ùå Las funciones de Google Drive no est√°n disponibles. Aseg√∫rate de que 'modules.utils.drive_utils' est√© correctamente configurado.")


    # L√≥gica para ejecutar el scraping al presionar el bot√≥n
    if buscar_btn and st.session_state.urls_input:
        urls = [url.strip() for url in st.session_state.urls_input.split("\n") if url.strip()]
        if urls: # Asegurarse de que hay URLs despu√©s de limpiar
            with st.spinner("üîÑ Scrapeando datos de hoteles con Playwright..."):
                # Llama a la funci√≥n de scraping usando Playwright
                resultados = obtener_datos_booking(urls)
                st.session_state.resultados_json = resultados
            # Usar rerun para actualizar la interfaz y mostrar los resultados/botones
            st.experimental_rerun()
        else:
            st.warning("Por favor, introduce al menos una URL.")


    # Mostrar resultados en formato JSON si existen
    if st.session_state.resultados_json:
        st.subheader("üì¶ Resultados obtenidos")
        st.json(st.session_state.resultados_json)

# Ejemplo de c√≥mo podr√≠as llamar a render_scraping_booking si este archivo es el script principal de Streamlit
# if __name__ == "__main__":
#     render_scraping_booking()
