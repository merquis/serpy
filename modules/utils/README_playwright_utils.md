# 游꿠 M칩dulo Reutilizable de Playwright

Este m칩dulo (`playwright_utils.py`) proporciona funciones gen칠ricas para capturar HTML usando Playwright, dise침ado para ser reutilizado por diferentes scrapers sin duplicar c칩digo.

## 游늶 Caracter칤sticas

- **Configuraci칩n flexible**: Personaliza timeouts, selectores de espera, headers, etc.
- **Manejo de errores robusto**: Gesti칩n consistente de errores y timeouts
- **Procesamiento en lote**: Capacidad para procesar m칰ltiples URLs concurrentemente
- **F치cil integraci칩n**: API simple para usar en cualquier scraper

## 游 Uso B치sico

### 1. Importar el m칩dulo

```python
from modules.utils.playwright_utils import (
    PlaywrightConfig,
    obtener_html_simple,
    procesar_urls_en_lote,
    crear_config_booking,
    crear_config_generica
)
```

### 2. Obtener HTML de una URL

```python
import asyncio
from modules.utils.playwright_utils import obtener_html_simple

async def mi_scraper():
    # Obtener HTML con configuraci칩n por defecto
    resultado, html = await obtener_html_simple("https://example.com")
    
    if resultado.get("error"):
        print(f"Error: {resultado['error']}")
    else:
        print(f"HTML obtenido: {len(html)} caracteres")
        # Procesar el HTML con BeautifulSoup...

# Ejecutar
asyncio.run(mi_scraper())
```

### 3. Configuraci칩n personalizada

```python
from modules.utils.playwright_utils import PlaywrightConfig, obtener_html_simple

# Crear configuraci칩n personalizada
config = PlaywrightConfig(
    wait_for_selector=".content-loaded",  # Esperar a que aparezca este selector
    timeout=45000,  # 45 segundos de timeout
    wait_until="networkidle",  # Esperar a que no haya actividad de red
    user_agent="Mi Bot Personalizado/1.0",
    extra_headers={
        "Accept-Language": "es-ES",
        "Custom-Header": "valor"
    }
)

resultado, html = await obtener_html_simple("https://example.com", config)
```

### 4. Procesar m칰ltiples URLs

```python
urls = [
    "https://example.com/page1",
    "https://example.com/page2",
    "https://example.com/page3"
]

# Procesar con m치ximo 3 p치ginas concurrentes
resultados = await procesar_urls_en_lote(urls, config, max_concurrent=3)

for resultado, html in resultados:
    if resultado.get("error"):
        print(f"Error en {resultado['url_original']}: {resultado['error']}")
    else:
        print(f"칄xito en {resultado['url_original']}: {len(html)} caracteres")
```

## 游닀 API Reference

### `PlaywrightConfig`

Clase de configuraci칩n con los siguientes par치metros:

- `headless` (bool): Ejecutar en modo sin ventana. Default: `True`
- `timeout` (int): Timeout para cargar la p치gina en ms. Default: `60000`
- `wait_until` (str): Evento a esperar. Opciones: `"load"`, `"domcontentloaded"`, `"networkidle"`. Default: `"networkidle"`
- `user_agent` (str): User-Agent personalizado
- `accept_language` (str): Header Accept-Language. Default: `"es-ES,es;q=0.9,en;q=0.8"`
- `ignore_https_errors` (bool): Ignorar errores HTTPS. Default: `True`
- `wait_for_selector` (str): Selector CSS a esperar antes de capturar HTML
- `wait_for_timeout` (int): Timeout para wait_for_selector en ms. Default: `15000`
- `extra_headers` (dict): Headers HTTP adicionales

### Funciones principales

#### `obtener_html_simple(url, config=None)`
Obtiene HTML de una sola URL.

**Returns**: `Tuple[Dict, str]` - (resultado_dict, html_content)

#### `procesar_urls_en_lote(urls, config=None, max_concurrent=5)`
Procesa m칰ltiples URLs en lote.

**Returns**: `List[Tuple[Dict, str]]` - Lista de tuplas (resultado_dict, html_content)

#### `obtener_html_con_playwright(url, browser_instance, config=None)`
Funci칩n de bajo nivel que requiere una instancia de browser existente.

### Funciones helper

#### `crear_config_booking()`
Crea una configuraci칩n optimizada para Booking.com

#### `crear_config_generica(wait_for_selector=None, timeout=30000)`
Crea una configuraci칩n gen칠rica personalizable

## 游댢 Ejemplos de Integraci칩n

### Ejemplo 1: Scraper de Booking (ya implementado)

```python
# En scraping_booking.py
from modules.utils.playwright_utils import crear_config_booking, obtener_html_simple

async def obtener_datos_booking(url):
    config = crear_config_booking()
    resultado, html = await obtener_html_simple(url, config)
    
    if not resultado.get("error"):
        soup = BeautifulSoup(html, "html.parser")
        # Parsear datos espec칤ficos de Booking...
```

### Ejemplo 2: Scraper de e-commerce

```python
from modules.utils.playwright_utils import PlaywrightConfig, procesar_urls_en_lote

async def scrapear_productos(urls_productos):
    # Configuraci칩n para esperar a que los precios se carguen
    config = PlaywrightConfig(
        wait_for_selector=".price-tag",
        wait_until="networkidle",
        timeout=30000
    )
    
    resultados = await procesar_urls_en_lote(urls_productos, config)
    
    productos = []
    for resultado, html in resultados:
        if not resultado.get("error"):
            soup = BeautifulSoup(html, "html.parser")
            # Extraer informaci칩n del producto...
            productos.append(extraer_datos_producto(soup))
    
    return productos
```

### Ejemplo 3: Scraper de noticias

```python
async def scrapear_articulo_noticia(url):
    # Configuraci칩n r치pida para sitios de noticias
    config = PlaywrightConfig(
        wait_until="domcontentloaded",  # No esperar a todas las im치genes
        timeout=20000,
        wait_for_selector="article"  # Esperar al contenido principal
    )
    
    resultado, html = await obtener_html_simple(url, config)
    # Procesar art칤culo...
```

## 游냍 Manejo de Errores

El m칩dulo retorna errores estructurados:

```python
{
    "error": "Tipo_De_Error",
    "url_original": "https://example.com",
    "details": "Descripci칩n detallada del error"
}
```

Tipos de error comunes:
- `HTML_Vacio`: No se obtuvo contenido HTML
- `Timeout_Playwright`: Timeout al cargar la p치gina
- `Excepcion_Playwright_[Tipo]`: Excepci칩n espec칤fica de Playwright
- `Excepcion_Gather`: Error al procesar en lote
- `Resultado_Inesperado`: Resultado no esperado

## 游눠 Mejores Pr치cticas

1. **Usa configuraciones espec칤ficas**: Crea configuraciones adaptadas a cada sitio web
2. **Maneja los errores**: Siempre verifica si hay errores antes de procesar el HTML
3. **Limita la concurrencia**: No uses m치s de 5-10 p치ginas concurrentes
4. **Optimiza los selectores**: Usa selectores espec칤ficos para reducir tiempos de espera
5. **Considera el modo headless**: Usa `headless=True` para mejor rendimiento

## 游닇 Notas

- El m칩dulo usa Chromium por defecto
- Aseg칰rate de tener Playwright instalado: `pip install playwright`
- Instala los navegadores: `playwright install chromium`
