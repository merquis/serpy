# scraping_urls_manuales.py

import streamlit as st
import json
from scraper_tags_common import seleccionar_etiquetas_html, scrape_tags_from_url

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ§¬ Extraer etiquetas desde URLs pegadas manualmente
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
def render_scraping_urls_manuales():
    st.title("ğŸ§¬ Extraer etiquetas SEO desde URLs pegadas manualmente")
    st.markdown("Pega una o mÃ¡s URLs separadas por coma o lÃ­nea nueva")

    urls_input = st.text_area("ğŸ“¥ Pega aquÃ­ las URLs", height=120, placeholder="https://ejemplo.com, https://otro.com")
    etiquetas = seleccionar_etiquetas_html()

    if not etiquetas:
        st.info("â„¹ï¸ Selecciona al menos una etiqueta para extraer.")
        return

    if st.button("ğŸ” Extraer etiquetas"):
        if not urls_input.strip():
            st.warning("âš ï¸ No se han introducido URLs.")
            return

        # Separar por coma o salto de lÃ­nea
        urls = [u.strip() for u in urls_input.replace("\n", ",").split(",") if u.strip()]

        resultados = [scrape_tags_from_url(url, etiquetas) for url in urls]

        st.subheader("ğŸ“¦ Resultados obtenidos")
        st.json(resultados)

        nombre_salida = "etiquetas_urls_pegadas.json"
        st.download_button(
            label="â¬‡ï¸ Descargar JSON",
            data=json.dumps(resultados, indent=2, ensure_ascii=False).encode("utf-8"),
            file_name=nombre_salida,
            mime="application/json"
        )
